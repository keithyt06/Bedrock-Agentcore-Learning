{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# 在 Amazon Bedrock AgentCore Runtime 中托管使用 Amazon Bedrock 模型的 LangGraph 代理\n",
    "\n",
    "## 概述\n",
    "\n",
    "在本教程中，我们将学习如何使用 Amazon Bedrock AgentCore Runtime 托管您现有的代理。\n",
    "\n",
    "我们将重点关注使用 Amazon Bedrock 模型的 LangGraph 示例。有关使用 Amazon Bedrock 模型的 Strands Agents 示例，请查看[这里](../01-strands-with-bedrock-model)，\n",
    "有关使用 OpenAI 模型的 Strands Agents 示例，请查看[这里](../03-strands-with-openai-model)。\n",
    "\n",
    "### 教程详情\n",
    "\n",
    "| 信息             | 详情                                                                      |\n",
    "|:--------------------|:-----------------------------------------------------------------------------|\n",
    "| 教程类型       | 对话式                                                               |\n",
    "| 代理类型          | 单一                                                                       |\n",
    "| 代理框架   | LangGraph                                                                    |\n",
    "| LLM 模型           | Anthropic Claude Sonnet 3                                                    |\n",
    "| 教程组件 | 在 AgentCore Runtime 上托管代理。使用 LangGraph 和 Amazon Bedrock 模型 |\n",
    "| 教程领域   | 跨领域                                                               |\n",
    "| 示例复杂度  | 简单                                                                         |\n",
    "| 使用的 SDK            | Amazon BedrockAgentCore Python SDK 和 boto3                                 |\n",
    "\n",
    "### 教程架构\n",
    "\n",
    "在本教程中，我们将描述如何将现有代理部署到 AgentCore runtime。\n",
    "\n",
    "出于演示目的，我们将使用带有 Amazon Bedrock 模型的 LangGraph 代理\n",
    "\n",
    "在我们的示例中，我们将使用一个非常简单的代理，它有两个工具：`get_weather` 和 `get_time`。\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_runtime.png\" width=\"50%\"/>\n",
    "</div>\n",
    "\n",
    "### 教程主要特点\n",
    "\n",
    "* 在 Amazon Bedrock AgentCore Runtime 上托管代理\n",
    "* 使用 Amazon Bedrock 模型\n",
    "* 使用 LangGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## 先决条件\n",
    "\n",
    "要执行本教程，您需要：\n",
    "* Python 3.10+\n",
    "* AWS 凭证\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* LangGraph\n",
    "* Docker 运行中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#!uv add -r requirements.txt --active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## 创建代理并在本地进行实验\n",
    "\n",
    "在将代理部署到 AgentCore Runtime 之前，让我们先在本地开发和运行它们进行实验。\n",
    "\n",
    "对于生产级代理应用程序，我们需要将代理创建过程与代理调用过程分离。使用 AgentCore Runtime，我们将使用 `@app.entrypoint` 装饰器装饰代理的调用部分，并将其作为我们运行时的入口点。让我们首先看看在实验阶段如何开发每个代理。\n",
    "\n",
    "这里的架构将如下所示：\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_local.png\" width=\"50%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d386ab54e85e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile langgraph_bedrock.py\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import argparse\n",
    "import json\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# Create calculator tool\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate the result of a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression as a string (e.g., \"2 + 3 * 4\", \"sqrt(16)\", \"sin(pi/2)\")\n",
    "    \n",
    "    Returns:\n",
    "        The result of the calculation as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define safe functions that can be used in expressions\n",
    "        safe_dict = {\n",
    "            \"__builtins__\": {},\n",
    "            \"abs\": abs, \"round\": round, \"min\": min, \"max\": max,\n",
    "            \"sum\": sum, \"pow\": pow,\n",
    "            # Math functions\n",
    "            \"sqrt\": math.sqrt, \"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan,\n",
    "            \"log\": math.log, \"log10\": math.log10, \"exp\": math.exp,\n",
    "            \"pi\": math.pi, \"e\": math.e,\n",
    "            \"ceil\": math.ceil, \"floor\": math.floor,\n",
    "            \"degrees\": math.degrees, \"radians\": math.radians,\n",
    "            # Basic operators (for explicit use)\n",
    "            \"add\": operator.add, \"sub\": operator.sub,\n",
    "            \"mul\": operator.mul, \"truediv\": operator.truediv,\n",
    "        }\n",
    "        \n",
    "        # Evaluate the expression safely\n",
    "        result = eval(expression, safe_dict)\n",
    "        return str(result)\n",
    "        \n",
    "    except ZeroDivisionError:\n",
    "        return \"Error: Division by zero\"\n",
    "    except ValueError as e:\n",
    "        return f\"Error: Invalid value - {str(e)}\"\n",
    "    except SyntaxError:\n",
    "        return \"Error: Invalid mathematical expression\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create a custom weather tool\n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\"Get weather\"\"\"  # Dummy implementation\n",
    "    return \"sunny\"\n",
    "\n",
    "# Define the agent using manual LangGraph construction\n",
    "def create_agent():\n",
    "    \"\"\"Create and configure the LangGraph agent\"\"\"\n",
    "    from langchain_aws import ChatBedrock\n",
    "    \n",
    "    # Initialize your LLM (adjust model and parameters as needed)\n",
    "    llm = ChatBedrock(\n",
    "        model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",  # or your preferred model\n",
    "        model_kwargs={\"temperature\": 0.1}\n",
    "    )\n",
    "    \n",
    "    # Bind tools to the LLM\n",
    "    tools = [calculator, weather]\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # System message\n",
    "    system_message = \"You're a helpful assistant. You can do simple math calculation, and tell the weather.\"\n",
    "    \n",
    "    # Define the chatbot node\n",
    "    def chatbot(state: MessagesState):\n",
    "        # Add system message if not already present\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_message)] + messages\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Create the graph\n",
    "    graph_builder = StateGraph(MessagesState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "    graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    # Add edges\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "    \n",
    "    # Set entry point\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent()\n",
    "\n",
    "def langgraph_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    \n",
    "    # Create the input in the format expected by LangGraph\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    \n",
    "    # Extract the final message content\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    response = langgraph_bedrock(json.loads(args.payload))\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68499675-db8d-47c6-8c0c-5d66dcb06229",
   "metadata": {},
   "source": [
    "#### 调用本地代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226d59e6b56c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:52:06.461281Z",
     "start_time": "2025-06-29T21:52:06.456854Z"
    }
   },
   "outputs": [],
   "source": [
    "!python langgraph_bedrock.py '{\"prompt\": \"What is the weather now?\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## 准备代理以部署到 AgentCore Runtime\n",
    "\n",
    "现在让我们将代理部署到 AgentCore Runtime。为此，我们需要：\n",
    "* 使用 `from bedrock_agentcore.runtime import BedrockAgentCoreApp` 导入 Runtime App\n",
    "* 在代码中使用 `app = BedrockAgentCoreApp()` 初始化 App\n",
    "* 使用 `@app.entrypoint` 装饰器装饰调用函数\n",
    "* 让 AgentCoreRuntime 使用 `app.run()` 控制代理的运行\n",
    "\n",
    "### 使用 Amazon Bedrock 模型的 LangGraph\n",
    "让我们从使用 Amazon Bedrock 模型的 LangGraph 开始。其他使用不同框架和模型的示例可在父目录中找到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile langgraph_bedrock.py\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "import argparse\n",
    "import json\n",
    "import operator\n",
    "import math\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Create calculator tool\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate the result of a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression as a string (e.g., \"2 + 3 * 4\", \"sqrt(16)\", \"sin(pi/2)\")\n",
    "    \n",
    "    Returns:\n",
    "        The result of the calculation as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define safe functions that can be used in expressions\n",
    "        safe_dict = {\n",
    "            \"__builtins__\": {},\n",
    "            \"abs\": abs, \"round\": round, \"min\": min, \"max\": max,\n",
    "            \"sum\": sum, \"pow\": pow,\n",
    "            # Math functions\n",
    "            \"sqrt\": math.sqrt, \"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan,\n",
    "            \"log\": math.log, \"log10\": math.log10, \"exp\": math.exp,\n",
    "            \"pi\": math.pi, \"e\": math.e,\n",
    "            \"ceil\": math.ceil, \"floor\": math.floor,\n",
    "            \"degrees\": math.degrees, \"radians\": math.radians,\n",
    "            # Basic operators (for explicit use)\n",
    "            \"add\": operator.add, \"sub\": operator.sub,\n",
    "            \"mul\": operator.mul, \"truediv\": operator.truediv,\n",
    "        }\n",
    "        \n",
    "        # Evaluate the expression safely\n",
    "        result = eval(expression, safe_dict)\n",
    "        return str(result)\n",
    "        \n",
    "    except ZeroDivisionError:\n",
    "        return \"Error: Division by zero\"\n",
    "    except ValueError as e:\n",
    "        return f\"Error: Invalid value - {str(e)}\"\n",
    "    except SyntaxError:\n",
    "        return \"Error: Invalid mathematical expression\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create a custom weather tool\n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\"Get weather\"\"\"  # Dummy implementation\n",
    "    return \"sunny\"\n",
    "\n",
    "# Define the agent using manual LangGraph construction\n",
    "def create_agent():\n",
    "    \"\"\"Create and configure the LangGraph agent\"\"\"\n",
    "    from langchain_aws import ChatBedrock\n",
    "    \n",
    "    # Initialize your LLM (adjust model and parameters as needed)\n",
    "    llm = ChatBedrock(\n",
    "        model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",  # or your preferred model\n",
    "        model_kwargs={\"temperature\": 0.1}\n",
    "    )\n",
    "    \n",
    "    # Bind tools to the LLM\n",
    "    tools = [calculator, weather]\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # System message\n",
    "    system_message = \"You're a helpful assistant. You can do simple math calculation, and tell the weather.\"\n",
    "    \n",
    "    # Define the chatbot node\n",
    "    def chatbot(state: MessagesState):\n",
    "        # Add system message if not already present\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_message)] + messages\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Create the graph\n",
    "    graph_builder = StateGraph(MessagesState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "    graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    # Add edges\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "    \n",
    "    # Set entry point\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent()\n",
    "\n",
    "@app.entrypoint\n",
    "def langgraph_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    \n",
    "    # Create the input in the format expected by LangGraph\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    \n",
    "    # Extract the final message content\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "## 幕后发生了什么？\n",
    "\n",
    "当您使用 `BedrockAgentCoreApp` 时，它会自动：\n",
    "\n",
    "* 创建一个监听 8080 端口的 HTTP 服务器\n",
    "* 实现处理代理需求所需的 `/invocations` 端点\n",
    "* 实现用于健康检查的 `/ping` 端点（对于异步代理非常重要）\n",
    "* 处理适当的内容类型和响应格式\n",
    "* 根据 AWS 标准管理错误处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "## 将代理部署到 AgentCore Runtime\n",
    "\n",
    "`CreateAgentRuntime` 操作支持全面的配置选项，让您可以指定容器镜像、环境变量和加密设置。您还可以配置协议设置（HTTP、MCP）和授权机制，以控制客户端如何与代理通信。\n",
    "\n",
    "**注意：** 操作最佳实践是将代码打包为容器并使用 CI/CD 管道和 IaC 推送到 ECR\n",
    "\n",
    "在本教程中，我们将使用 Amazon Bedrock AgentCode Python SDK 轻松打包您的构件并将它们部署到 AgentCore runtime。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0861401-a111-4ade-9e02-50f52fdfa9b1",
   "metadata": {},
   "source": [
    "### 创建运行时角色\n",
    "\n",
    "在开始之前，让我们为 AgentCore Runtime 创建一个 IAM 角色。我们将使用为您预先开发的 utils 函数来实现这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Get the current notebook's directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "\n",
    "# Navigate up to the utils.py location\n",
    "utils_dir = os.path.join(current_dir, '..')\n",
    "utils_dir = os.path.abspath(utils_dir)\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, utils_dir)\n",
    "\n",
    "from utils import create_agentcore_role\n",
    "\n",
    "agent_name=\"langgraph_bedrock\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "### 配置 AgentCore Runtime 部署\n",
    "\n",
    "接下来，我们将使用我们的启动工具包配置 AgentCore Runtime 部署，包括入口点、我们刚刚创建的执行角色和一个需求文件。我们还将配置启动工具包在启动时自动创建 Amazon ECR 存储库。\n",
    "\n",
    "在配置步骤中，将根据您的应用程序代码生成 docker 文件\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/configure.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "region\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"langgraph_bedrock.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### 将代理启动到 AgentCore Runtime\n",
    "\n",
    "现在我们已经有了 docker 文件，让我们将代理启动到 AgentCore Runtime。这将创建 Amazon ECR 存储库和 AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result = agentcore_runtime.launch()\n",
    "launch_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "### 检查 AgentCore Runtime 状态\n",
    "现在我们已经部署了 AgentCore Runtime，让我们检查它的部署状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### 调用 AgentCore Runtime\n",
    "\n",
    "最后，我们可以使用有效负载调用我们的 AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/invoke.png\" width=75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"How much is 2+2?\"})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "### 处理调用结果\n",
    "\n",
    "我们现在可以处理我们的调用结果，以将其包含在应用程序中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249103-cfb3-47b5-970d-981a977a225a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "response_text = json.loads(invoke_response['response'][0].decode(\"utf-8\"))\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "### 使用 boto3 调用 AgentCore Runtime\n",
    "\n",
    "现在您的 AgentCore Runtime 已创建，您可以使用任何 AWS SDK 调用它。例如，您可以使用 boto3 的 `invoke_agent_runtime` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84e68d-6c04-41b9-bf5b-60edc3fa0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps({\"prompt\": \"What is the weather now?\"})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        if line:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data: \"):\n",
    "                line = line[6:]\n",
    "                logger.info(line)\n",
    "                content.append(line)\n",
    "    display(Markdown(\"\\n\".join(content)))\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## 清理（可选）\n",
    "\n",
    "现在让我们清理创建的 AgentCore Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86824-c775-4ad4-aaee-f18e8cf390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=agentcore_role_name,\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "iam_response = iam_client.delete_role(\n",
    "    RoleName=agentcore_role_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# 恭喜！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}